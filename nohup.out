block 0, size : 96 16 16
range = 2.886751345948129
block 1, size : 384 8 8
range = 0.8505172717997146
block 2, size : 1536 4 4
range = 0.4252586358998573
block 3, size : 6114 2 2
range = 0.21262931794992865
range = 0.11075616624431513

 ----- Architecture Block BatchNorm2dSK3962(5, 5)1.0reflect, number 0 -----
- BatchNorm2d(3, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)
- HebbSoftKrotovConv2d(3, 96, lebesgue_p=2, pruning=0, kernel_size=(5, 5), bias=False, padding_mode=reflect, t_invert=1.0, bias=False, lr_bias=0.1, ranking_param=3, delta=2, activation=exp)
- Triangle(power=0.7)
- MaxPool2d(kernel_size=4, stride=2, padding=1, dilation=1, ceil_mode=False)

 ----- Architecture Block BatchNorm2dSK963842(3, 3)0.6499999761581421reflect, number 1 -----
- BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)
- HebbSoftKrotovConv2d(96, 384, lebesgue_p=2, pruning=0, kernel_size=(3, 3), bias=False, padding_mode=reflect, t_invert=0.6499999761581421, bias=False, lr_bias=0.1538, ranking_param=3, delta=2, activation=exp)
- Triangle(power=1.4)
- MaxPool2d(kernel_size=4, stride=2, padding=1, dilation=1, ceil_mode=False)

 ----- Architecture Block BatchNorm2dSK38415362(3, 3)0.25reflect, number 2 -----
- BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)
- HebbSoftKrotovConv2d(384, 1536, lebesgue_p=2, pruning=0, kernel_size=(3, 3), bias=False, padding_mode=reflect, t_invert=0.25, bias=False, lr_bias=0.4, ranking_param=3, delta=2, activation=exp)
- Triangle(power=1.0)
- AvgPool2d(kernel_size=2, stride=2, padding=0)

 ----- Architecture Block BatchNorm2dSK153661142(3, 3)0.25reflect, number 3 -----
- BatchNorm2d(1536, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)
- HebbSoftKrotovConv2d(1536, 6114, lebesgue_p=2, pruning=0, kernel_size=(3, 3), bias=False, padding_mode=reflect, t_invert=0.25, bias=False, lr_bias=0.4, ranking_param=3, delta=2, activation=exp)
- Triangle(power=1.0)
- AvgPool2d(kernel_size=2, stride=2, padding=0)

 ----- Architecture Block FlattenDropout(p=0.5, inplace=False)Linear(in_, number 4 -----
- Flatten(start_dim=1, end_dim=-1)
- Dropout(p=0.5, inplace=False)
- Linear(in_features=24456, out_features=10, bias=True)

 ********** Hebbian Unsupervised learning of blocks [0] **********
Files already downloaded and verified
Epoch: [1/1]	lr: 1.44e-01	time: 00:01:09	Acc_train 0.00	Acc_test 0.00	convergence: 2.40e+01	R1: 0	Info MB:0.000e+00/SB:0.000e+00/MW:1.185e-02/SW:5.668e-01/MR:4.631e+00/SR:1.640e+00/MeD:1.262e+00/MaD:3.631e+00/MW:0.606/MAW:0.394
|       0 |       1 |       2 |       3 |       4 |       5 |       6 |       7 |       8 |      9 |      10 |      11 |     12 |      13 |      14 |      15 |         16 |      17 |      18 |      19 |     20 |      21 |      22 |      23 |      24 |         25 |      26 |     27 |      28 |      29 |
|---------+---------+---------+---------+---------+---------+---------+---------+---------+--------+---------+---------+--------+---------+---------+---------+------------+---------+---------+---------+--------+---------+---------+---------+---------+------------+---------+--------+---------+---------|
|   0.187 |   0.136 |   0.121 |   0.112 |   0.167 |   0.107 |   0.148 |   0.198 |   0.176 |   0.2  |   0.156 |   0.169 |   0.16 |   0.128 |   0.134 |   0.158 |   5.52e-05 |   0.197 |   0.163 |   0.172 |   0.17 |   0.166 |   0.141 |   0.182 |   0.203 |   3.38e-05 |   0.185 |   0.12 |   0.128 |   0.169 |
|   6.45  |   3.91  |   3.28  |   2.96  |   5.37  |   2.8   |   4.42  |   7.14  |   5.85  |   7.27 |   4.8   |   5.47  |   5.02 |   3.55  |   3.82  |   4.91  |   1        |   7.09  |   5.13  |   5.65  |   5.52 |   5.32  |   4.11  |   6.17  |   7.43  |   1        |   6.33  |   3.26 |   3.56  |   5.45  |
|   0.57  |   0.49  |   0.53  |   0.55  |   0.55  |   0.64  |   0.53  |   0.52  |   0.56  |   0.52 |   0.65  |   0.52  |   0.43 |   0.52  |   0.53  |   0.47  |  19.01     |   0.55  |   0.53  |   0.54  |   0.54 |   0.56  |   0.49  |   0.54  |   0.53  |  24.34     |   0.37  |   0.55 |   0.56  |   0.49  |
| nan     | nan     | nan     | nan     | nan     | nan     | nan     | nan     | nan     | nan    | nan     | nan     | nan    | nan     | nan     | nan     | nan        | nan     | nan     | nan     | nan    | nan     | nan     | nan     | nan     | nan        | nan     | nan    | nan     | nan     |
| nan     | nan     | nan     | nan     | nan     | nan     | nan     | nan     | nan     | nan    | nan     | nan     | nan    | nan     | nan     | nan     | nan        | nan     | nan     | nan     | nan    | nan     | nan     | nan     | nan     | nan        | nan     | nan    | nan     | nan     |
| nan     | nan     | nan     | nan     | nan     | nan     | nan     | nan     | nan     | nan    | nan     | nan     | nan    | nan     | nan     | nan     | nan        | nan     | nan     | nan     | nan    | nan     | nan     | nan     | nan     | nan        | nan     | nan    | nan     | nan     |


 ********** Hebbian Unsupervised learning of blocks [1] **********
Files already downloaded and verified
Epoch: [1/1]	lr: 1.44e-01	time: 00:02:17	Acc_train 0.00	Acc_test 0.00	convergence: 2.40e+01	R1: 0	Info MB:0.000e+00/SB:0.000e+00/MW:4.990e-03/SW:1.532e-01/MR:4.238e+00/SR:1.535e+00/MeD:1.227e+00/MaD:4.116e+00/MW:0.595/MAW:0.405
|         0 |        1 |         2 |          3 |         4 |        5 |         6 |         7 |         8 |        9 |        10 |        11 |        12 |      13 |       14 |        15 |        16 |        17 |        18 |       19 |       20 |       21 |        22 |       23 |        24 |       25 |       26 |        27 |       28 |        29 |
|-----------+----------+-----------+------------+-----------+----------+-----------+-----------+-----------+----------+-----------+-----------+-----------+---------+----------+-----------+-----------+-----------+-----------+----------+----------+----------+-----------+----------+-----------+----------+----------+-----------+----------+-----------|
|   0.00321 |   0.0111 |   0.00779 |   0.000604 |   0.00647 |   0.0105 |   0.00375 |   0.00513 |   0.00988 |   0.0052 |   0.00791 |   0.00329 |   0.00626 |   0.011 |   0.0086 |   0.00958 |   0.00727 |   0.00961 |   0.00253 |   0.0102 |   0.0104 |   0.0105 |   0.00928 |   0.0124 |   0.00892 |   0.0114 |   0.0101 |   0.00986 |   0.0117 |   0.00787 |
|   1.41    |   5.93   |   3.43    |   1.01     |   2.68    |   5.39   |   1.56    |   2.05    |   4.9     |   2.08   |   3.5     |   1.43    |   2.57    |   5.83  |   3.96   |   4.67    |   3.11    |   4.7     |   1.26    |   5.19   |   5.31   |   5.42   |   4.44    |   7.19   |   4.18    |   6.17   |   5.11   |   4.89    |   6.44   |   3.48    |
|   0.22    |   0.18   |   0.15    |   0.42     |   0.33    |   0.16   |   0.14    |   0.16    |   0.15    |   0.19   |   0.2     |   0.19    |   0.2     |   0.22  |   0.17   |   0.17    |   0.14    |   0.2     |   0.16    |   0.21   |   0.18   |   0.21   |   0.28    |   0.22   |   0.34    |   0.25   |   0.22   |   0.19    |   0.16   |   0.2     |
| nan       | nan      | nan       | nan        | nan       | nan      | nan       | nan       | nan       | nan      | nan       | nan       | nan       | nan     | nan      | nan       | nan       | nan       | nan       | nan      | nan      | nan      | nan       | nan      | nan       | nan      | nan      | nan       | nan      | nan       |
| nan       | nan      | nan       | nan        | nan       | nan      | nan       | nan       | nan       | nan      | nan       | nan       | nan       | nan     | nan      | nan       | nan       | nan       | nan       | nan      | nan      | nan      | nan       | nan      | nan       | nan      | nan      | nan       | nan      | nan       |
| nan       | nan      | nan       | nan        | nan       | nan      | nan       | nan       | nan       | nan      | nan       | nan       | nan       | nan     | nan      | nan       | nan       | nan       | nan       | nan      | nan      | nan      | nan       | nan      | nan       | nan      | nan      | nan       | nan      | nan       |


 ********** Hebbian Unsupervised learning of blocks [2] **********
Files already downloaded and verified
Epoch: [1/1]	lr: 4.90e-02	time: 00:03:31	Acc_train 0.00	Acc_test 0.00	convergence: 2.40e+01	R1: 0	Info MB:0.000e+00/SB:0.000e+00/MW:1.037e-02/SW:2.876e-01/MR:1.679e+01/SR:2.065e+00/MeD:1.609e+00/MaD:1.579e+01/MW:0.432/MAW:0.568
|        0 |        1 |        2 |        3 |        4 |        5 |        6 |       7 |        8 |        9 |       10 |       11 |       12 |       13 |       14 |       15 |      16 |       17 |       18 |       19 |       20 |      21 |       22 |       23 |       24 |       25 |       26 |       27 |       28 |       29 |
|----------+----------+----------+----------+----------+----------+----------+---------+----------+----------+----------+----------+----------+----------+----------+----------+---------+----------+----------+----------+----------+---------+----------+----------+----------+----------+----------+----------+----------+----------|
|   0.0441 |   0.0411 |   0.0405 |   0.0369 |   0.0399 |   0.0428 |   0.0408 |   0.036 |   0.0409 |   0.0429 |   0.0428 |   0.0407 |   0.0374 |   0.0367 |   0.0383 |   0.0407 |   0.039 |   0.0419 |   0.0398 |   0.0431 |   0.0416 |   0.039 |   0.0398 |   0.0411 |   0.0401 |   0.0404 |   0.0406 |   0.0373 |   0.0372 |   0.0388 |
|  20.48   |  17.86   |  17.43   |  14.62   |  16.9    |  19.29   |  17.64   |  13.96  |  17.72   |  19.43   |  19.31   |  17.55   |  15      |  14.5    |  15.65   |  17.53   |  16.2   |  18.52   |  16.82   |  19.56   |  18.27   |  16.25  |  16.86   |  17.87   |  17.07   |  17.33   |  17.46   |  14.91   |  14.86   |  16.05   |
|   0.05   |   0.05   |   0.05   |   0.05   |   0.05   |   0.05   |   0.07   |   0.03  |   0.06   |   0.08   |   0.08   |   0.07   |   0.12   |   0.06   |   0.11   |   0.04   |   0.05  |   0.08   |   0.05   |   0.04   |   0.07   |   0.07  |   0.06   |   0.05   |   0.05   |   0.05   |   0.06   |   0.07   |   0.03   |   0.03   |
| nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan     | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan     | nan      | nan      | nan      | nan      | nan     | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      |
| nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan     | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan     | nan      | nan      | nan      | nan      | nan     | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      |
| nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan     | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan     | nan      | nan      | nan      | nan      | nan     | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      |


 ********** Hebbian Unsupervised learning of blocks [3] **********
Files already downloaded and verified
Epoch: [1/1]	lr: 3.96e-02	time: 00:05:42	Acc_train 0.00	Acc_test 0.00	convergence: 1.81e+01	R1: 5	Info MB:0.000e+00/SB:0.000e+00/MW:1.425e-03/SW:1.639e-01/MR:1.907e+01/SR:2.735e+00/MeD:2.047e+00/MaD:1.807e+01/MW:0.455/MAW:0.545
|        0 |        1 |        2 |        3 |        4 |        5 |        6 |        7 |        8 |        9 |       10 |       11 |       12 |       13 |       14 |       15 |       16 |       17 |       18 |       19 |       20 |       21 |       22 |       23 |       24 |       25 |       26 |       27 |       28 |       29 |
|----------+----------+----------+----------+----------+----------+----------+----------+----------+----------+----------+----------+----------+----------+----------+----------+----------+----------+----------+----------+----------+----------+----------+----------+----------+----------+----------+----------+----------+----------|
|   0.0408 |   0.0437 |   0.0401 |   0.0428 |   0.0448 |   0.0432 |   0.0458 |   0.0432 |   0.0389 |   0.0402 |   0.0484 |   0.0454 |   0.0398 |   0.0454 |   0.0446 |   0.0433 |   0.0464 |   0.0435 |   0.0447 |   0.0449 |   0.0425 |   0.0309 |   0.0448 |   0.0427 |   0.0406 |   0.0413 |   0.0431 |   0.0419 |   0.0432 |   0.0436 |
|  17.66   |  20.08   |  17.11   |  19.31   |  21.08   |  19.64   |  22.02   |  19.66   |  16.1    |  17.2    |  24.41   |  21.59   |  16.81   |  21.58   |  20.85   |  19.73   |  22.56   |  19.88   |  20.94   |  21.14   |  19.1    |  10.53   |  21.05   |  19.25   |  17.5    |  18.09   |  19.56   |  18.52   |  19.64   |  19.97   |
|   0.01   |   0.02   |   0.02   |   0.02   |   0.01   |   0.01   |   0.01   |   0.02   |   0.01   |   0.01   |   0.02   |   0.02   |   0.01   |   0.01   |   0.01   |   0.01   |   0.01   |   0.03   |   0.02   |   0.03   |   0.02   |   0.02   |   0.01   |   0.01   |   0.01   |   0.01   |   0.02   |   0.01   |   0.01   |   0.02   |
| nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      |
| nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      |
| nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      | nan      |


 ********** Supervised learning of blocks [4] **********
Files already downloaded and verified
Epoch: [1/50]	lr: 1.00e-03	time: 00:06:02	Loss_train 0.42146	Acc_train 56.79	/	Loss_test 0.02009	Acc_test 67.14
Epoch: [10/50]	lr: 1.00e-03	time: 00:08:17	Loss_train 0.49031	Acc_train 70.24	/	Loss_test 0.03250	Acc_test 73.98
Epoch: [20/50]	lr: 2.50e-04	time: 00:10:47	Loss_train 0.37880	Acc_train 76.92	/	Loss_test 0.02020	Acc_test 79.15
Epoch: [30/50]	lr: 1.25e-04	time: 00:13:16	Loss_train 0.27845	Acc_train 79.43	/	Loss_test 0.01753	Acc_test 80.07
Epoch: [40/50]	lr: 3.13e-05	time: 00:15:46	Loss_train 0.22623	Acc_train 80.92	/	Loss_test 0.01617	Acc_test 80.41
Epoch: [50/50]	lr: 7.81e-06	time: 00:18:15	Loss_train 0.21304	Acc_train 81.28	/	Loss_test 0.01586	Acc_test 80.69
